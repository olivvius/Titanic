{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score of rf using crossvalidations : 0.8362 \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-8d7786bdf066>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;31m# Predicting the Test set results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;31m# Save the results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;31m#results <- data.frame(PassengerID = titanic[892:1309,\"PassengerId\"], Survived = y_pred)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    627\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m         \"\"\"\n\u001b[1;32m--> 629\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    419\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[0;32m    390\u001b[0m                                 X.indptr.dtype != np.intc):\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    646\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     95\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     96\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m     98\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "# IMPORT\n",
    "import pandas as pd\n",
    "import statistics as st\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# DATAS\n",
    "train=pd.read_csv('train.csv',sep=',')\n",
    "test=pd.read_csv('test.csv',sep=',')\n",
    "train.set_index('PassengerId',inplace=True,drop=True)\n",
    "#print(train.columns)\n",
    "train.dtypes\n",
    "#print(train.size)\n",
    "#print(train.ndim)\n",
    "\n",
    "####\n",
    "def parse_model_4(X):\n",
    "    target = X.Survived\n",
    "    X['title'] = X.Name.map(lambda x : x.split(',')[1].split('.')[0])\n",
    "    X['surname'] = X.Name.map(lambda x : '(' in x)\n",
    "    X['Cabin'] = X.Cabin.map(lambda x : x[0] if not pd.isnull(x) else -1)\n",
    "    to_dummy = ['Pclass', 'Sex', 'title', 'Embarked', 'Cabin']\n",
    "    for dum in to_dummy :\n",
    "        split_feature = pd.get_dummies(X[dum],prefix='split_'+dum)\n",
    "        X = X.join(split_feature)\n",
    "        del X[dum]\n",
    "    X['Age'] = X.Age.fillna(X.Age.median())\n",
    "    X['is_child'] = X.Age < 16\n",
    "    to_del = ['Name', 'Survived', 'Ticket']\n",
    "    for col in to_del : del X[col]\n",
    "    return X, target\n",
    "def parse_model_test(X):\n",
    "    X['title'] = X.Name.map(lambda x : x.split(',')[1].split('.')[0])\n",
    "    X['surname'] = X.Name.map(lambda x : '(' in x)\n",
    "    X['Cabin'] = X.Cabin.map(lambda x : x[0] if not pd.isnull(x) else -1)\n",
    "    to_dummy = ['Pclass', 'Sex', 'title', 'Embarked', 'Cabin']\n",
    "    for dum in to_dummy :\n",
    "        split_feature = pd.get_dummies(X[dum],prefix='split_'+dum)\n",
    "        X = X.join(split_feature)\n",
    "        del X[dum]\n",
    "    X['Age'] = X.Age.fillna(X.Age.median())\n",
    "    X['is_child'] = X.Age < 16\n",
    "    to_del = ['Name', 'Ticket']\n",
    "    for col in to_del : del X[col]\n",
    "    return X\n",
    "####\n",
    "X,y=parse_model_4(train)\n",
    "Xtest=parse_model_test(test)\n",
    "#write.csv(Xtest,file='testrefined.csv')\n",
    "#print(Xtest)\n",
    "####\n",
    "def compute_score(clf, X, y):\n",
    "    xval = cross_val_score(clf, X, y, cv = 10)\n",
    "    return np.mean(xval)\n",
    "\n",
    "\n",
    "###\n",
    "rf=RandomForestClassifier(n_estimators=250,max_depth=8)\n",
    "rf.fit(X,y)\n",
    "\n",
    "print(\"score of rf using crossvalidations : {:.4f} \".format(compute_score(rf, X, y)))\n",
    "#Importance of variables in Random forest\n",
    "def clf_importance(X, clf):\n",
    "    import pylab as pl\n",
    "    importances = clf.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    for f in range(X.shape[1]):\n",
    "        print(\"%d. feature : %s (%f)\" % (f +1, X.columns[indices[f]],importances[indices[f]]))\n",
    "        \n",
    "###       \n",
    "#clf_importance(X,rf)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = rf.predict(Xtest)\n",
    "# Save the results\n",
    "#results <- data.frame(PassengerID = titanic[892:1309,\"PassengerId\"], Survived = y_pred)\n",
    "\n",
    "# Write the results to a csv file\n",
    "#write.csv(results, file = 'PredictingTitanicSurvival.csv', row.names = FALSE, quote=FALSE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'max_depth': 8, 'n_estimators': 250}\n",
      "\n",
      "\n",
      "0.798 + or -0.024 for the {'max_depth': 2, 'n_estimators': 5}\n",
      "0.773 + or -0.019 for the {'max_depth': 2, 'n_estimators': 10}\n",
      "0.793 + or -0.026 for the {'max_depth': 2, 'n_estimators': 50}\n",
      "0.78 + or -0.021 for the {'max_depth': 2, 'n_estimators': 100}\n",
      "0.789 + or -0.02 for the {'max_depth': 2, 'n_estimators': 250}\n",
      "0.795 + or -0.021 for the {'max_depth': 4, 'n_estimators': 5}\n",
      "0.813 + or -0.017 for the {'max_depth': 4, 'n_estimators': 10}\n",
      "0.814 + or -0.019 for the {'max_depth': 4, 'n_estimators': 50}\n",
      "0.815 + or -0.019 for the {'max_depth': 4, 'n_estimators': 100}\n",
      "0.815 + or -0.021 for the {'max_depth': 4, 'n_estimators': 250}\n",
      "0.82 + or -0.011 for the {'max_depth': 8, 'n_estimators': 5}\n",
      "0.815 + or -0.027 for the {'max_depth': 8, 'n_estimators': 10}\n",
      "0.825 + or -0.018 for the {'max_depth': 8, 'n_estimators': 50}\n",
      "0.833 + or -0.019 for the {'max_depth': 8, 'n_estimators': 100}\n",
      "0.834 + or -0.019 for the {'max_depth': 8, 'n_estimators': 250}\n",
      "0.813 + or -0.024 for the {'max_depth': 16, 'n_estimators': 5}\n",
      "0.816 + or -0.017 for the {'max_depth': 16, 'n_estimators': 10}\n",
      "0.824 + or -0.024 for the {'max_depth': 16, 'n_estimators': 50}\n",
      "0.824 + or -0.027 for the {'max_depth': 16, 'n_estimators': 100}\n",
      "0.823 + or -0.027 for the {'max_depth': 16, 'n_estimators': 250}\n",
      "0.797 + or -0.015 for the {'max_depth': 32, 'n_estimators': 5}\n",
      "0.815 + or -0.037 for the {'max_depth': 32, 'n_estimators': 10}\n",
      "0.814 + or -0.034 for the {'max_depth': 32, 'n_estimators': 50}\n",
      "0.814 + or -0.037 for the {'max_depth': 32, 'n_estimators': 100}\n",
      "0.816 + or -0.033 for the {'max_depth': 32, 'n_estimators': 250}\n",
      "0.792 + or -0.036 for the {'max_depth': None, 'n_estimators': 5}\n",
      "0.809 + or -0.023 for the {'max_depth': None, 'n_estimators': 10}\n",
      "0.81 + or -0.026 for the {'max_depth': None, 'n_estimators': 50}\n",
      "0.807 + or -0.028 for the {'max_depth': None, 'n_estimators': 100}\n",
      "0.815 + or -0.029 for the {'max_depth': None, 'n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "#GridSearchCV\n",
    "parameters = { \"n_estimators\":[5,10,50,100,250],\"max_depth\":[2,4,8,16,32,None]}\n",
    "cv = GridSearchCV(rf,parameters,cv=5)\n",
    "cv.fit(X,y)\n",
    "def display(results):\n",
    "    print(f'Best parameters are: {results.best_params_}')\n",
    "    print(\"\\n\")\n",
    "    mean_score = results.cv_results_['mean_test_score']\n",
    "    std_score = results.cv_results_['std_test_score']\n",
    "    params = results.cv_results_['params']\n",
    "    for mean,std,params in zip(mean_score,std_score,params):\n",
    "        print(f'{round(mean,3)} + or -{round(std,3)} for the {params}')\n",
    "        \n",
    "display(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
